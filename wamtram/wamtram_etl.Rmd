---
title: "Turtle Tagging ETL"
author: "Turtle Conservation Program, Dept Parks & Wildlife WA"
date: "`r format(Sys.time(), '%d %B, %Y %H:%M')`"
output: html_document
---
```{r r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ckanr)

# Spatial analysis
library(rgdal)
library(sp)
library(maptools)

# Data management goes last to mask shared functions
library(Hmisc)
library(htmlTable)
library(httr)
library(plyr)
library(dplyr)
library(lubridate)
library(stringr)
library(tidyjson)
library(jsonlite)
library(tibble)
library(rvest)

library(tidyverse)
library(magrittr)

# Visualisation
library(DT)
# library(mapview)
library(leaflet)
require(leaflet.extras)
# library(trelliscope)
library(RColorBrewer)

library(RODBC)
if (file.exists("~/.Rprofile")) source("~/.Rprofile")
if (file.exists(here::here("config", "setup.R"))) source(here::here("config", "setup.R"))
```

This document describes and executes the Extraction, Transformation and (up)Loading
of data from the Turtle Tagging database WAMTRAM 2 to the data catalogue.

It is based on technical documentation provided by WAMTRAM 1 developer Simon Woodman.

# Installation
Setup RODBC as per
[the instructions](http://itsalocke.com/install-sql-server-odbc-drivers-travis-ci/)
and configure an ODBC data source for the tagging database, e.g.

* in Windows: Control Panel > ODBC Data Sources,
* Linux: create `~/.odbc.ini`:

```{r, eval=F}
[turtle_tagging]
Driver = FreeTDS
Server = kensmssql001pro.corporateict.domain
Port = 1433
```

See also the
[RODBC vigette](https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf).

# Purpose
The purpose of this document is to outline the code contained within the
SQL Server WA Marine Turtles Database. Primarily the code is for the processing
of Turtle observation records captured using the Microsoft Access application
developed by Pendoley Environmental. Originally the main Turtle database
application had a "flat-file" base data entry process, but this was subsequently
replaced by the Pendoley Environmental application.
Problems with the transfer of data from the data entry program into the main d
atabase prompted a re-development of the process, which is described in this document.

# Field data ingestion

```{r}
con <- odbcConnect("turtle_tagging", uid=Sys.getenv("W2_UN"), pwd=Sys.getenv("W2_PW"))
entry_batches <- sqlQuery(con, 'select * from dbo.TRT_ENTRY_BATCHES')
data_entry <- sqlQuery(con, 'select * from dbo.TRT_DATA_ENTRY')
data_entry_operators <- sqlQuery(con, 'select * from TRT_DATA_ENTRY_PERSONS')
```

Data is transferred from the data entry file into holding tables in the
SQL Server database for processing via the main WA Marine Turtles application.
It supports both the old flat-file format and the Pendoley data entry program format.
See the main WA Marine Turtles documentation for details on that functionality.

There are 3 tables involved in the holding and used during the processing of the data entry records.
During processing data is copied from these tables to the tables of the main application.
Those details of those tables are not contained within this document.

## `TRT_ENTRY_BATCHES`
Records are loaded from a data entry and processed in a single batch.
This table contains a single record per batch and stores a few basic details
about the batch such as the filename from where the records were loaded,
and whether the observation date uses the PR (Pendoley Rawcliffe) Date Convention.
**Note** For nesting turtles observed after midnight, the Pendoley Rawcliffe
date convention uses the previous dayâ€™s date.

## `TRT_DATA_ENTRY`
This table contains the records of turtle observations.
All recordable attributes are stored in a single record for each observation.
The fields `TURTLE_ID` and `OBSERVATION_ID` are populated during the process described in 2.2.1.
If the record has not been successfully transferred to the main data tables,
the fields `ERROR_NUMBER` and `ERROR_MESSAGE` will be populated instead.

## `TRT_DATA_ENTRY_PERSONS`
This table stores a list of people appearing in the data entry records for each batch.
Individual people are defined in the `TRT_PERSONS` table.
Historically there was an issue with the `TRT_PERSONS` table being populated by a
large number of duplicate records.

The re-development addressed this issue by using the `TRT_DATA_ENTRY_PERSONS`
table to define the unique people recorded in each batch,
along with the mapping to the appropriate record in the `TRT_PERSONS` table.
The records in this table are partially populated by the main WA Marine Turtles
application, and interactively by the user performing the processing of the batch.

## Data entry summary
There are `r nrow(entry_batches)` batches of data presently loaded,
providing `r nrow(data_entry)` records for ingestion from
`r nrow(data_entry_operators)` field data entry operators.

# Business logic
This section describes the "Stored Procedures" of the tagging database.

The data is loaded from the data entry file via the Microsoft Access admin front-end,
but the processing of each record is performed by SQL Server stored procedures.

## `dbo.EntryBatchProcess`
This is the main stored procedure that copies the data from the holding tables
into the main application tables, updating the fields
`TURTLE_ID`, `OBSERVATION_ID`, `ERROR_NUMBER` and `ERROR_MESSAGE`
where appropriate to indicate success or failure of the process.

The stored procedure loops through all records in the `TRT_DATA_ENTRY` table for
a specified batch.  If a record fails validation or an unexpected error occurs,
the `ERROR_NUMBER` and `ERROR_MESSAGE` fields are populated and the process
continues on to the next record.

If the record is successfully processed then the resulting values for `TURLTE_ID`
and `OBSERVATION_ID` are stored in the record.

The stored procedure can be run multiple times on the same batch, as records with 
existing `TURTLE_ID` and `OBSERVATION_ID` are skipped. 
Records that have previously failed are reprocessed.

This stored procedure is run from a button in the main WA Marine Turtles application.

## `dbo.ValidateDataEntryBatch`
This routine loops through all the records in the `TRT_DATA_ENTRY` table for a 
specified batch and attempts to validate each record.

Data is not transferred into the main application tables; however the
`ERROR_NUMBER` and `ERROR_MESSAGE` fields are populated for problem records.

In this way the user can check all the records in the batch before deciding to
load any data in the main application tables.

## `dbo.ValidateDataEntryRecord`
This routine validates the values entered for a single record in the 
`TRT_DATA_ENTRY` table, and is called by the dbo.ValidateDataEntryBatch stored 
procedure.

## `dbo.CheckPerson`
This routine checks the `TRT_PERSONS` table for an existing record and returns
the value of the primary key (`PERSON_ID)`.

## `dbo.EntryBatchAddExistingTag`: apply a new flipper tag during capture
A helper routine for the stored procedure `dbo.EntryBatch` that adds a single record
to the `TRT_RECORDED_TAGS` table, and updates the status of the respective
record in the `TRT_TAGS` table.

This is run when a new flipper tag has been attached to a turtle.

## `dbo.EntryBatchAddNewTag`: re-sight an attached flipper tag during re-capture
A helper routine for the stored procedure `dbo.EntryBatch` that adds a single record
to the `TRT_RECORDED_TAGS` table.

This is run when a previously attached flipper tag is recorded.

## `dbo.ValidateIdentification`
A helper routine for the `dbo.EntryBatch` stored procedure that validates other
turtle identification types (i.e. identification other than flipper or pit tags).

## `dbo.ValidateMeasurement`
Validates measurements against minimum and maximum values stored in the 
`dbo.TRT_MEASUREMENT_TYPES` table.

## `dbo.ValidateFloatRange`
A generic function for validating that the FLOAT value falls within an acceptable range.

## `dbo.ValidateIntegerRange`
A generic function for validating that the INTEGER falls within an acceptable range.

## `dbo.FlipperTagExists`
A function for determining whether or not a flipper tag exists in the `TRT_TAGS` table.

## `dbo.PitTagExists`
A function for determining whether or not a pit tag exists in the `TRT_PIT_TAGS` table.

## Calculated Fields in Tables
Scalar-valued Functions

###`dbo.ObservationStatus`
This function returns one of the following values for the status of an observation:

* Initial Nesting,
* Initial Sighting,
* Remigrant, or
* Resighting.

The function is used to populate the value of the `TRT_OBSERVATIONS.OBSERVATION_STATUS` field.

## Views
There are several summary views in the database that utilise stored procedures.

## Stored Procedures
### `dbo.InterseasonRemigration`
This is a summary function that displays the history of inter-season remigration
for each turtle recorded in the system. It is used by the view `TRV_INTERSEASON_MIGRATION`.

### `dbo.ObservationTags`
This is a summary function that returns a list of tags recorded for a turtle for 
a given observation.
It is not currently used.

## Other Functionality: Stored Procedures

### `dbo.TransferObservationsByFlipperTag`
Changes in the database structure between WAMTRAM v1 and v2
introduced modified referential integrity constraints between the tables
`TRT_OBSERVATIONS`, `TRT_TAGS` and `TRT_RECORDED_TAGS` table.
This had the benefit of ensuring valid data between these tables,
whereas previously data in the `TRT_RECORDED_TAGS` table was allowed to be
inconsistent with data in the other two tables.

The reasoning behind this was to reflect data actually captured by the users,
and data recording problems could be analysed and reviewed via an exceptions report.

The downside to the change was that records that were found to have been assigned
to the wrong turtle could not be easily be corrected.
Records had to be completely deleted from the database and re-entered,
so a stored procedure was developed to handle this.

**Note** End of Simon's technical docs.

# Data
This section aims to extract the raw data from the database.

Note: WAMTRAM 1 tables are prefixed with `TRT_*` following departmental naming 
conventions, whereas Pendoley-Rawcliffe tables are prefixed with `tbl*` as per
common MS Access naming convention.
There exists duplication of records between the two sets of tables.

## Sites
Nesting beaches are stored in table `TRT_PLACES`.
```{r}
sites <- sqlQuery(con, "select * from dbo.TRT_PLACES;") %>%
  dplyr::rename(
    prefix=LOCATION_CODE,
    name=PLACE_CODE,
    label=PLACE_NAME,
    is_rookery=ROOKERY,
    beach_approach=BEACH_APPROACH,
    beach_aspect=ASPECT,
    site_datum=DATUM_CODE,
    site_latitude=LATITUDE,
    site_longitude=LONGITUDE,
    comments=COMMENTS
  )

sites_with_coordinates <- sites %>% dplyr::filter(!is.na(site_latitude))
ico <- makeAwesomeIcon(icon="cog", library="glyphicon")
leaflet(sites_with_coordinates) %>%
  addProviderTiles("Esri.WorldImagery") %>%
  setView(lng=120, lat=-20, zoom=5) %>%
  addAwesomeMarkers(~site_longitude, ~site_latitude, label=~label, icon=ico)
```

Some sites are missing coordinates and need to be fixed in `TRT_PLACES`:

```{r}
badsites <- sites %>% filter(is.na(site_latitude) | is.na(site_longitude))
DT::datatable(badsites)
```

Most of these are offshore, in-water captures/releases.

**TODO** The database custodian (BP) needs to sit with a GIS analyst to
digitise all `r nrow(sites)` sites as polygons. 
The site polygons shall be delineated by:

* The exact extent of the location as a segment of the high water mark.
* A well-chosen buffer of the high water mark to accommodate observations 
  both at low tide (buffer seawards) and encounters with nesting turtles.
* The polygons shall be simplified to consist of exactly one polygon ring and 
  not overlap with each other.

## Tag status mapping
TODO: Review and update WAMTRAM to WAStD stag status mapping.

```{r}
ts <- sqlQuery(con, "select * from dbo.TRT_TAG_STATES;")
ts %>% DT::datatable()
```

## Observations
Ancillary lookup tables are sanitised and joined to the observations.

```{r}
# Sensitive information!
persons <- sqlQuery(con, "select * from dbo.TRT_PERSONS;")
# save(persons, file = "data/persons.Rda")
# load("data/persons.Rda")
person_names <- persons %>%
    transmute(
        PERSON_ID=PERSON_ID,
        name=paste(FIRST_NAME, SURNAME) %>% 
          str_replace_all("[<>()*=?]", "") %>% str_trim(),
        email=EMAIL %>% str_replace("NA", "") %>% str_trim())
person_details <- persons %>%
    mutate(
        name=paste(FIRST_NAME, SURNAME) %>% 
          str_replace_all("[<>()*=?]", "") %>% str_trim(),
        email=EMAIL %>% str_replace("NA", "") %>% str_trim())

activities <- sqlQuery(
    con, "select * from dbo.TRT_ACTIVITIES;") %>%
  transmute(
    activity_code=ACTIVITY_CODE,
    activity_description=DESCRIPTION,
    activity_is_nesting=NESTING,
    activity_label=New_Code,
    display_this_observation=Display_Observation)

beach_positions <- sqlQuery(
    con, "select * from dbo.TRT_BEACH_POSITIONS;") %>%
  transmute(
    beach_position_code=BEACH_POSITION_CODE,
    beach_position_description=DESCRIPTION,
    beach_position_label=New_Code)

conditions <-  sqlQuery(
    con, "select * from dbo.TRT_CONDITION_CODES;") %>%
  transmute(
    condition_code=CONDITION_CODE,
    condition_label=DESCRIPTION)

egg_count_methods <-  sqlQuery(
    con, "select * from dbo.TRT_EGG_COUNT_METHODS;") %>%
  transmute(
    egg_count_method_code=EGG_COUNT_METHOD,
    egg_count_method_label=DESCRIPTION)

body_parts <- sqlQuery(
    con, "select * from dbo.TRT_BODY_PARTS;") %>%
  transmute(
    body_part_code=BODY_PART,
    body_part_label=DESCRIPTION,
    is_flipper=FLIPPER)

# use native datum conversion instead
datum_codes <- sqlQuery(con, "select * from dbo.TRT_DATUM_CODES;")

# Tag types
id_types <- sqlQuery(
    con, "select * from dbo.TRT_IDENTIFICATION_TYPES;") %>%
  transmute(
    id_type_code=IDENTIFICATION_TYPE,
    id_type_label=DESCRIPTION)

# 220k+ records
recorded_tags <- sqlQuery(
    con, "select * from dbo.TRT_RECORDED_TAGS;") %>%
  transmute(
    recorded_tag_id=RECORDED_TAG_ID,
    observation_id=OBSERVATION_ID,
    tag_name=TAG_ID,
    tag_label=OTHER_TAG_ID,
    attached_on_side=SIDE,
    tag_state=TAG_STATE,
    tag_position=TAG_POSITION,
    comments=COMMENTS
  )
# save(recorded_tags, file="data/tag_observations.Rda")
# load("data/tag_observations.Rda")


# 55k+ inferred turtle identities
turtles <- sqlQuery(con, "select * from dbo.TRT_TURTLES;")
summary(turtles)

tags <- sqlQuery(con, "select * from dbo.TRT_TAGS;")

samples <- sqlQuery(con, "select * from dbo.TRT_SAMPLES;")
sample_tissue_type <- sqlQuery(con, "select * from dbo.TRT_TISSUE_TYPES;")

pit_tags <- sqlQuery(con, "select * from dbo.TRT_PIT_TAGS;")
recorded_pit_tags <- sqlQuery(con, "select * from dbo.TRT_RECORDED_PIT_TAGS;")
pit_tag_states <- sqlQuery(con, "select * from dbo.TRT_PIP_TAG_STATES;")
```

Observations.
```{r}
measurement_types <- sqlQuery(
    con, "select * from dbo.TRT_MEASUREMENT_TYPES;") %>%
  transmute(
    measurement_type_code=MEASUREMENT_TYPE,
    measurement_type_label=DESCRIPTION,
    physical_unit=MEASUREMENT_UNITS,
    min_value=MINIMUM_VALUE,
    max_value=MAXIMUM_VALUE,
    comments=COMMENTS)

measurements <- sqlQuery(
    con, "select * from dbo.TRT_MEASUREMENTS;") %>%
  transmute(
    observation_id=OBSERVATION_ID,
    measurement_type_code=MEASUREMENT_TYPE,
    value=MEASUREMENT_VALUE,
    comments=COMMENTS)


damage_codes <- sqlQuery(con, "select * from dbo.TRT_DAMAGE_CODES;")
damage_causes <- sqlQuery(con, "select * from dbo.TRT_DAMAGE_CAUSE_CODES;")
damages <- sqlQuery(con, "select * from dbo.TRT_DAMAGE;")

# 147k+
obs <- sqlQuery(con, "select * from dbo.TRT_OBSERVATIONS;")

# save all objects
# save.image("data/wamtram_all.RData")
# resume
# load("data/wamtram_all.RData")

ord <- c("YmdHMS", "Ymd")
utc <- "UTC"
gmt08 <- "Australia/Perth"

o <- obs %>%
    dplyr::mutate(
        o_date=parse_date_time(CORRECTED_DATE, orders=ord, tz=gmt08),
        o_time=parse_date_time(OBSERVATION_TIME, orders=ord, tz=gmt08),
        observation_datetime_gmt08=o_date - days(1) + hours(hour(o_time)) + minutes(minute(o_time)),
        observation_datetime_utc=with_tz(observation_datetime_gmt08, tz=utc)
    ) %>%
    dplyr::select(
        -OBSERVATION_DATE, -OBSERVATION_DATE_OLD, -DATE_CONVENTION,
        -CORRECTED_DATE, -OBSERVATION_TIME, -o_date, -o_time
    ) %>%
    dplyr::rename(
        activity_code=ACTIVITY_CODE
    ) %>%
    dplyr::left_join(activities, by="activity_code") %>%
    # left_join(person_names, by=c("MEASURER_PERSON_ID" = "PERSON_ID")) %>%
    # rename(measured_by=name) %>%
    # left_join(person_names, by=c("MEASURER_REPORTER_PERSON_ID" = "PERSON_ID")) %>%
    # rename(measurements_reported_by=name) %>%
    # left_join(person_names, by=c("TAGGER_PERSON_ID" = "PERSON_ID")) %>%
    # rename(tagged_by=name) %>%
    # left_join(person_names, by=c("REPORTER_PERSON_ID" = "PERSON_ID")) %>%
    # rename(reported_by=name) %>%
    left_join(sites, by=c("PLACE_CODE" = "name")) %>%
    left_join(turtles, by="TURTLE_ID") %>%
    mutate(
      LATITUDE = ifelse(is.na(LATITUDE), site_latitude, LATITUDE),
      LONGITUDE = ifelse(is.na(LONGITUDE), site_longitude, LONGITUDE)
      )

# save(o, file="data/encounters.Rda")
# load("data/encounters.Rda")

# TODO reconstruct empty DD from DMS or UTM or site coords

encounters <- o %>% 
  filter(!is.na(LONGITUDE)) %>% 
  filter(!is.na(LATITUDE)) %>% 
  filter(!is.na(observation_datetime_utc)) %>%
  arrange(desc(observation_datetime_utc))

encounters_missing <- o %>% 
  filter(is.na(LONGITUDE) | is.na(LATITUDE) | is.na(observation_datetime_utc)) %>%
  arrange(desc(observation_datetime_utc))

encounters_missing %>% skimr::skim()

```


* obs with OTHER_TAGS_IDENTIFICATION_TYPE == "STRAND/SAL" are untagged strandings
* TRT_IDENTIFICATION_TYPES = TAG_TYPE

```{r}
DT::datatable(sites)
```


# Upload data

```{r upload_data}
d <- package_show("wa-marine-turtle-tagging-database-wamtram-2")
# write.csv(enc2, file = here::here("wamtram", "data", "wamtram_encounters_incomplete.csv"), row.names = F)
# write.csv(o, file = here::here("wamtram", "data", "wamtram_encounters.csv"), row.names = F)
# ckanr::resource_update(Sys.getenv("W2_ENC_CSV_RID"), here::here("wamtram", "data", "wamtram_encounters.csv"))

# Users
users_fn <- here::here("wamtram", "data", "wamtram_users.csv")
readr::write_csv(person_details, users_fn)
# r <- resource_create(package_id=d$id, name="WAMTRAM Users", upload=users_fn)
ckanr::resource_update("ca523326-623f-460e-a617-77d403918b81", users_fn)

# Encounters
enc_fn <- here::here("wamtram", "data", "wamtram_encounters.csv")
readr::write_csv(encounters, enc_fn)
# r <- resource_create(package_id=d$id, name="WAMTRAM Encounters", upload=enc_fn)
ckanr::resource_update("f7e30448-de1c-4061-8a85-887632934961", enc_fn)

# Tags
tag_fn <- here::here("wamtram", "data", "wamtram_tagobservations.csv")
readr::write_csv(recorded_tags, tag_fn)
# r <- resource_create(package_id=d$id, name="WAMTRAM Tags", upload=tag_fn)
ckanr::resource_update("6d2e2c24-7d10-4a73-8711-12bc03120fa1", tag_fn)
```

# Products
This section outlines the desired products to be created from the tagging data.

## Gorgon control charts
For the Gorgon reports, the following products are generated:

* Adult survival rate: annual survival probability vs time
* Breeding omission rate: annual breeding probability vs time
* Annual nesters (Barrow Island): flatback nesters vs time
* Mean clutch frequency (Barrow Island): clutches per female vs time
* Egg hatchling rate: annual hatchling probability vs time
* Hatchling emergence rate: annual emergence probability
* Daily count at terminal / at bivalve: GLMM standardised index vs time
* Hatchling disorientation at terminal / at bivalve: fan spread (Yeo-Johnson tf) vs time
* Hatchling misorientation at terminal / at bivalve: fan offset (Y-J tf)
* Sand temperature at 50 cm at Mushroom / terminal / bivalve / yacht club north / yc south / overall vs time
* Intra-seasonal dynamics: Within season arrival probabilities: probability vs time

## Tag history
For tags (tag IDs = rows), one column per year, value 0 (not encountered) or 1 (encountered),
plus columns for location and species.
