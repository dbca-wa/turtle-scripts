---
title: "Report Title"
author: "Report Author"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    fig_width: 10
    fig_height: 6
    code_folding: hide
    theme: lumen
  pdf_document:
    latex_engine: xelatex
  word_document: default
---
<!--  
This Rmd template provides an example workflow to access submissions and 
attachments of a given ODK Central form using its OData API and disseminate
data, attachments, and this report via CKAN or Google Drive.

You will need:
* An ODK Central form's OData Service URL (ending in .svc), accessed from the 
"Analyse using OData" button on the form submission tab.
* Username and password of an ODK Central webuser authorised to view this form.
* Optional: base URL and write-permitted API key for a CKAN instance.
* Optional: a Google account and the means to authenticate (e.g. phone for 2FA).
-->

<!--
Step 1: Setup ruODK, ckanr
Secrets are set as environment variables to keep them outside of this document. 
Read vignette "setup" for further information.
-->
<!-- 1a. Open the .Renviron file:  -->
```{r edit_renviron, echo=FALSE, eval=FALSE}
usethis::edit_r_environ()
```

<!-- 1b. Paste the following block usign your own, working credentials:  -->
```{r paste_env_vars, echo=FALSE, eval=FALSE}
# ODK Central web user with "manager" role on project
ODKC_UN="my@email.com"
ODKC_PW="my-odkc-password"

# CKAN user with permissions to create a dataset
CKAN_URL="https://demo.ckan.org"
CKAN_KEY="my-ckan-api-key"
```
<!-- 1c: Restart the R session to load these environment variables. -->

<!-- 
* Configure ODK Central base URL (url), project ID (pid), and form ID (fid) 
in one step using the OData Service URL.
* Paste your own Service URL over `svc="..."`.
* Paste your local timezone over `Australia/Perth`.
* Adjust `loc` to a local subfolder for downloaded attachments.
-->
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")

# All packages used in this example
library(ckanr)
library(dplyr)
library(DT)
library(fs)
library(googledrive)
library(knitr)
library(leaflet)
library(readr)
# library(skimr)
library(ruODK)

# Set ruODK defaults to an ODK Central form
ruODK::ru_setup(svc="https://odkcentral.dbca.wa.gov.au/v1/projects/2/forms/build_Field-Observation-0-1_1570512277.svc")
tz <- "Australia/Perth"
loc <- fs::path("attachments", "media")
fs::dir_create(loc)
```

# Download data
<!-- Get table names. `form_tables` will contain one row per separate table. -->
```{r svc_get}
form_tables <- ruODK::odata_service_get()
form_tables %>% knitr::kable(.)
```

<!-- 
Get and parse submissions.

* Rename any point coordinates which come out as `xn`, `xn+1`, `xn+2` into 
longitude, latitude, altitude.
* Repeat parse_datetime for each form field name that symbolises a datetime.
Default assumes "time", example shows an additional step to also parse any
form field with "date" in its name.


Repeat for each table name in form_tables$url. 
-->
```{r dl_submissions}
data <- ruODK::odata_submission_get(
  table = form_tables$url[1], verbose = TRUE, tz = tz, local_dir = loc
) %>%
  dplyr::rename(
    longitude = x9,
    latitude = x10,
    altitude = x11
  )

# data_sub1 <- ruODK::odata_submission_get(
#   table = form_tables$url[2], verbose = TRUE, tz = tz, local_dir = loc
# ) %>%
#   dplyr::left_join(data, by = c("submissions_id" = "id"))
# 
# data_sub2 <- ruODK::odata_submission_get(
#   table = form_tables$url[3], verbose = TRUE, tz = tz, local_dir = loc
# ) %>% 
#   dplyr::rename(
#     # Adjust coordinate colnames as needed, avoid name conflicts with main data
#     # lon = x6,
#     # lat = x7,
#     # alt = x8
#   ) %>%
#   dplyr::left_join(data, by = c("submissions_id" = "id"))

# repeat for any remaining nested tables
```

# Analyse data
<!-- Summarise, analyse, visualise the tibble(s) data (, data_sub1, data_sub2) -->
```{r data_vis}
# skimr::skim(data)
dplyr::glimpse(data)
DT::datatable(head(data))
```

```{r data_map}
leaflet::leaflet(width = 800, height = 600) %>%
  leaflet::addProviderTiles("OpenStreetMap.Mapnik", group = "Place names") %>%
  leaflet::addProviderTiles("Esri.WorldImagery", group = "Aerial") %>%
  leaflet::clearBounds() %>%
  leaflet::addAwesomeMarkers(
    data = data,
    lng = ~longitude, lat = ~latitude,
    icon = leaflet::makeAwesomeIcon(text = "Q", markerColor = "red"),
    # 
    # # With your own field names
    # 
    label = ~ glue::glue("{barcode} {start_time}"),
    popup = ~ glue::glue(
      "<h3>{sample_id}</h3>",
      "Survey start {start_time}</br>",
      "Reporter {submitter_name}</br>",
      "Device {device_id}</br>",
      "<h5>Site</h5>",
      '<div><img src="{photo}"',
      ' height="150px" alt="My photo"></img></div>'
    ),
    clusterOptions = leaflet::markerClusterOptions()
  ) %>%
  leaflet::addLayersControl(
    baseGroups = c("Place names", "Aerial"),
    options = leaflet::layersControlOptions(collapsed = FALSE)
  )
```

# Export
<!--
The form submissions are now extracted and visualised. What's next:

* Save data to local files (e.g. CSV).
* Compile report (e.g. to HTML).
* Compress all outputs as ZIP.
* Upload these artifacts to a CKAN data catalogue.
* Upload same artifacts to Google Drive.

Notes: 

* Generate the HTML report once off without the next chunk (`eval=F`), 
as the chunk refers to the rendered output file (HTML) before the file is 
created initially.
* Run report always twice to generate (run 1) and upload (run 2) the latest HTML.
-->
```{r data_export, eval=FALSE}
#------------------------------------------------------------------------------#
# Prepare report and products as local files
#
rep_fn <- "my_report.html" # The file name you save this template under
data_fn <- here::here(loc, "data.csv") %>% as.character()           # Main data
data_sub1_fn <- here::here(loc, "data_sub1.csv") %>% as.character() # Nested table 1
data_sub2_fn <- here::here(loc, "data_sub2.csv") %>% as.character() # Nested table 2
zip_fn <- "products.zip" # Attachments as one zip file (top level)

# Write data tbls to CSV files
readr::write_csv(data, path = data_fn)
readr::write_csv(data_sub1, path = data_sub1_fn)
readr::write_csv(data_sub2, path = data_sub2_fn)

# Compress everything into `zip_fn`, retain relative path to `loc`
zip(zipfile = zip_fn, files = fs::dir_ls(loc))

#------------------------------------------------------------------------------#
# CKAN
#
# Upload to a CKAN data catalogue (need url and API key of a write permitted user)
# See ROpenSci package ckanr
ckanr::ckanr_setup(url = Sys.getenv("CKAN_URL"), key = Sys.getenv("CKAN_KEY"))
ckan_ds_name <- "my-ckan-dataset-slug"

# Run once to create resources on an existing dataset, then comment out
d <- ckanr::package_show(ckan_ds_name)
res_data_main <- ckanr::resource_create(
  package_id = d$id, name="Main data", upload = data_fn)
res_data_sub1 <- ckanr::resource_create(
  package_id = d$id, name="Nested data table 1", upload = data_sub1_fn)
res_data_sub2 <- ckanr::resource_create(
  package_id = d$id, name="Nested data table 2", upload = data_sub2_fn)
res_report <- ckanr::resource_create(
  package_id = d$id, name="Data report", upload = rep_fn)
res_zip <- ckanr::resource_create(
  package_id = d$id, name="All data and attachments", upload = zip_fn)

# Paste res_data_main$id over RID and keep here, repeat for each resource
r <- ckanr::resource_update(res_data_main$id, path = data_fn)
r <- ckanr::resource_update(res_data_sub1$id, path = data_sub1_fn)
r <- ckanr::resource_update(res_data_sub2$id, path = data_sub2_fn)
r <- ckanr::resource_update(res_report$id, path = res_report)
r <- ckanr::resource_update(res_zip$id, path = zip_fn)

#------------------------------------------------------------------------------#
# Google Drive
#
# Run once per machine, then comment out:
googledrive::drive_auth(reset=TRUE, use_oob = TRUE)

# Upload to Google Drive
gd_fn <- "My Google Drive folder name"
googledrive::drive_ls(gd_fn) %>% googledrive::drive_rm(.)  # Wipe older outputs
googledrive::drive_upload(rep_fn, path=rep_fn)             # Report as HTML
googledrive::drive_upload(data_fn, path=data_fn)           # Main data as CSV
googledrive::drive_upload(data_sub1_fn, path=data_sub1_fn) # Nested table 1 as CSV
googledrive::drive_upload(data_sub2_fn, path=data_sub2_fn) # Nested table 2 as CSV
googledrive::drive_upload(zip_fn, path=zip_fn)             # All outputs as ZIP
```
