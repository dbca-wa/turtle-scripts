---
title: "Care for Hedland Season Review 2017-2018"
author: "Care for Hedland with Marine Turtles WA"
date: "`r Sys.time()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    fig_width: 10
    fig_height: 6
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
source("tracks_setup.R")
source("tracks_helpers.R")
source("load_data.R")
```

# Data
```{r load_data}
tr <- tracks_all %>% filter_realspecies() %>% add_nest_labels()
tracks_pth <- tr %>% filter_port_hedland_sites()
tracks_pth_cem <- tr %>% filter_port_hedland_cemetery()
tracks_pth_ppo <- tr %>% filter_port_hedland_prettypool()
surveys_pth <- surveys %>% filter_port_hedland_sites()
surveys_pth_prod <- surveys_pth %>% filter_realsurveys()
dist_pth <- disturbance %>% filter_port_hedland_sites()
nests_pth <- nests_all %>% filter_port_hedland_sites()

prefix <- "CFH"
placename <- "Port Hedland"
```

# QA
This section identifies tracks and disturbances outside known sites, missing surveys, and surveys requiring editing.
We show data from all regions as not to miss any stray records - ignore data not relevant to this analysis.

## Tracks outside known sites
Review whether there are stray tracks close to this program's sites.

* WAStD sites missing (new sites) or boundaries set too narrow. 
  Extend sites, re-save stray tracks to auto-repair their site affiliation.
* Training records close to site (but not meant to be within site).
  Change confirmed training records outside training areas to "Hatchback turtles" 
  and mark as "curated" to prevent from being overwritten by repeated data loading.
* Note: re-run uncached data import after changing tracks.

```{r tracks_missing_sites}
tracks_all %>% 
  filter_nosite() %>%
  filter_realspecies() %>%
  add_nest_labels() %>% 
  map_tracks()
```

## Disturbance outside known sites
Review disturbances close to this program's sites. It is safe to ignore other disturbances.

Disturbances can either be legitimate, although opportunistic, records, or training
records.

* Training records: set to "Other, see comments", mention "training" in comments,
  ideally instruct data collectors to photograph their writing board with "training"
  written on it to make absolutely clear that this record is a training record.

```{r dist_missing_sites}
disturbance %>% filter_nosite() %>% wastdr::map_dist()
```

## Surveys in WAStD
Curators are to QA 
[all `r placename` surveys on WAStD](https://tsc.dbca.wa.gov.au/admin/observations/survey/?site__id__in=35,45) following the 
[QA instructions for surveys](https://wastd.readthedocs.io/data_curators.html#data-flow-of-surveys).

Split up per site:

* [Cemetary Beach](https://tsc.dbca.wa.gov.au/admin/observations/survey/?site__id__exact=35)
* [Pretty Pool Beach](https://tsc.dbca.wa.gov.au/admin/observations/survey/?site__id__exact=45)

## Surveys missing end
Where a "Site Visit End" form was forgotten, `end_source_id` is empty, and the duration is set to 6h. 
These surveys should be closed a few minutes after the last recorded track or disturbance.

Surveys with missing end contribute to an over-estimation of survey effort.

This task will be automated soon.
  
```{r surveys_missing_end}
surveys_pth %>% 
  dplyr::filter(is.na(end_source_id)) %>%
  dplyr::select(-site_type, -site_id, -reporter_username, -reporter_id, -id, -absolute_admin_url) %>% 
  dt
```

## Provided username mismatches WAStD users
TODO: define QA rules for mismatches of usernames as (possibly mis)typed by data collectors vs 
[WAStD users](https://tsc.dbca.wa.gov.au/admin/users/user/).

```{r name_mismatch}
surveys_pth %>% filter_surveys_requiring_qa %>% dt
```


# Season summary

## General notes
Nests without a clearly visible emergence point were not recorded.
This led to under-reporting of hatched nests this season.

## Going digital
Entering and proofreading a record takes about 2 minutes with full concentration.
By going digital, data entry and proofreading are fully automated.
This season, the Care for Hedland Volunteers have saved Jo and the Kellies 
`r (nrow(tracks_pth) + nrow(surveys_pth)*2) * 2 / 60` hours of mind-numbing data entry
and proofreading work for `r nrow(tracks_pth)` Track or Treats and 
`r nrow(surveys_pth)*2` Site Visit Starts/Ends. 
This estimate excludes Fox Sakes and Marine Wildlife Incidents, about 2-3h extra!

## Maps
### Nesting at Cemetery Beach

```{r map_cem}
tracks_pth_cem %>% filter_2017() %>% map_tracks()
```

### Nesting at Pretty Pool Beach

```{r map_ppo}
tracks_pth_ppo %>% filter_2017() %>% map_tracks()
```


### Animated map
A [Google API key](https://developers.google.com/maps/documentation/geocoding/start?csw=1) must
be present as R environment variable `GOOGLE_MAPS_APIKEY` for the next step.

```{r map_animated}
ggmap::register_google(key = Sys.getenv("GOOGLE_MAPS_APIKEY"))

# basemap
bbx <- ggmap::make_bbox(longitude, latitude, tracks_pth, f = 0.05)
ctr <- c(mean(bbx["left"], bbx["right"]), mean(bbx["top"], bbx["bottom"]))
# basemap <- ggmap::get_map(ctr, zoom=17) %>% ggmap::ggmap()
basemap <- ggmap::get_googlemap(ctr, zoom = 15, scale = 2, maptype = "hybrid") %>%
  ggmap::ggmap()

# tracks
tracks_map <- suppressWarnings(
  basemap +
    geom_point(aes(longitude, latitude, colour = nest_type),
      data = tracks_pth, alpha = 0.8
    )
) +
  ggplot2::ggtitle("Turtle Nesting", subtitle = "Turtle date: {frame_time}") +
  gganimate::transition_time(turtle_date) +
  gganimate::ease_aes("linear")

# render and save
gganimate::animate(tracks_map, fps = 2) %T>%
  gganimate::anim_save(glue::glue("{prefix}_nesting.gif"), .)
```


### Tagged nests
2017-18: no tagged nests.

The map (once enabled) is saved as a PNG file `r glue::glue(prefix, "_tagged_nests.png")`.

```{r nests_all, eval=F}
nests_pth %>% map_nests() %>% mapview::mapshot(file=glue::glue("{prefix}_tagged_nests.png"))
```

## Nesting abundance

### All beaches
```{r tracks_all_sectors}
tracks_pth %>% species_by_type() %>% kable()
```

### Cemetery Beach
```{r tracks_cem}
tracks_pth_cem %>% species_by_type() %>% kable()
```

### Pretty Pool Beach
```{r tracks_ppo}
tracks_pth_ppo %>% species_by_type() %>% kable()
```

## Nesting success 
```{r nesting_success, warning = F}
tracks_pth %>% tracks_ts(placename, prefix)
tracks_pth_cem %>% tracks_ts("Cemetery Beach", prefix)
tracks_pth_ppo %>% tracks_ts("Pretty Pool Beach", prefix)

nests <- tracks_pth %>% track_success()

nests %>% ggplot_track_success_by_date("natator-depressus", placename, prefix)
nests %>% ggplot_track_successrate_by_date("natator-depressus", placename, prefix)
nests %>% track_success_by_species() %>% DT::datatable(.,
  caption = "Nesting success of fresh tracks (excl. nests without tracks and tagging)"
)
```

## Hatching and emergence success
```{r hatching_emergence_success}
tracks_pth %>%
  hatching_emergence_success() %>%
  kable
```

## Disturbance and predation
Disturbed nests are captured through form "Track or Treat" and appear here
as "tracks" with "disturbance" recorded as "present".

General signs of disturbance or predator presence are recorded through form 
"Fox Sake" and appear here as "dist_(place)".

### Disturbance and predation of nests
Turtle nests with recorded disturbance or predation.

```{r dist_nests}
disturbed_nests_pth <- tracks_pth %>% filter_2017() %>% filter(disturbance == "present")
disturbed_nests_pth %>% map_tracks()
```

There were **`r count(disturbed_nests_pth)` reports** of disturbed nests. 
Caveat: QA to exclude possible training records.

Coming soon: details of disturbance to nests.

### General disturbance
There were **`r count(dist_pth)` reports** of general disturbance or predator presence.

```{r map_dist}
dist_pth %>% filter_2017 %>% group_by(disturbance_cause) %>% tally %>% arrange(-n) %>% kable
dist_pth %>% map_dist
```

## Survey effort
### Caveat 
* Survey data includes training surveys. (Not production, but also effort)
* Surveys with missing end points are auto-closed after 5 hours (over-estimation of effort).
* Data excludes commute to survey site.

### Per season effort
Highest level of aggregation: entire season.

* Excluding training, there were **`r nrow(surveys_pth_prod)` surveys** to all beaches
  of the CfH program (Cemetery Beach and Pretty Pool Beach) over a period of **XXX days**.
  for a total duration of **`r sum(surveys_pth_prod$duration_hours)` hours**.
* Caveat: all training surveys must be marked as "not production" manually in WAStD.
  Above data currently may include training effort.

### Per day effort
Lowest level of aggregation: daily.

```{r survey_count}
surveys_pth %>% plot_survey_count(placename, prefix)
surveys_pth %>% list_survey_count(placename)
surveys_pth %>% plot_survey_effort(placename, prefix)
surveys_pth %>% list_survey_effort(placename)
```

### Individual surveys
No aggregation: individual surveys.

Note, a direct link to update each survey in WAStD is at the end of the table.

```{r survey_list}
surveys_pth %>% 
  dplyr::select(-site_type, -site_id, -reporter_username, -id, -absolute_admin_url) %>% 
  dt
```


## Volunteer effort
* Surveys including training runs represent volunteer effort.
* There were **`r surveys_pth %>% filter_2017() %>% nrow` surveys** 
  including training for a total duration of 
  **`r sum(filter_2017(surveys_pth_prod)$duration_hours)` hours**.
* At Cemetery Beach, **`r survey_ground_covered(surveys, 35, 1.6, season=2017)` km** were walked 
  in **`r survey_count(surveys_pth, 35, season=2017)`** surveys.
* At Pretty Pool Beach, **`r survey_ground_covered(surveys, 45, 1.8, season=2017)` km** were walked 
  in **`r survey_count(surveys_pth, 45, season=2017)`** surveys.

### Per person
The following list only includes the primary reporter. 
This leads to under-reporting of time spent by other volunteers attending the survey.
Their names are listed in the Site Visit Start form field "comments" as free text
(surveys > start_comments), and from 2018, in the Site Visit Start form field "team".

To correctly report on team member effort, curators have to read the list of 
team members in the Survey "start_comments" field and attach the correct users 
to the Survey's team list. From 2018, this will be automated but still requires QA.

Once the surveys are comprehensively attributed to all volunteers present, the code underneath this
workbook has to be updated to include the Survey team's effort.

If the primary reporter forgot to update the username in the tablet,
their survey effort on that day is incorrectly attributed to the previous reporter.
The only way to reconcile attribution is to manually compare survey usernames with team rosters.

```{r survey_effort_by_person}
personal_effort <- surveys_pth %>% filter_2017 %>% survey_hours_per_person()
personal_effort %>% kable()
```


# Data upload

## Raw data
* Raw data are exported into CSV spreadsheets.
* Key figures are exported into .png raster files.
* This report is rendered into a single HTML page.

```{r data_export_csv}
tracks_pth %>% dplyr::select(-obs, -photos) %>% 
  readr::write_csv(glue::glue("{prefix}_tracks.csv"))
surveys_pth %>% readr::write_csv(glue::glue("{prefix}_surveys.csv"))
dist_pth %>% dplyr::select(-photos) %>% 
  readr::write_csv(glue::glue("{prefix}_disturbance.csv"))
```

## Data catalogue
Data are uploaded to the [turtle nest census dataset](https://data.dpaw.wa.gov.au/dataset/turtle-tracks) 
on the departmental data catalogue, accessible from the DBCA intranet only.

```{r data_upload_ckan}
tracks_pth %>% dplyr::select(-obs, -photos) %>% 
  readr::write_csv(glue::glue("{prefix}_tracks.csv"))
surveys_pth %>% readr::write_csv(glue::glue("{prefix}_surveys.csv"))
dist_pth %>% dplyr::select(-photos) %>% 
  readr::write_csv(glue::glue("{prefix}_disturbance.csv"))

# Package all output files into one ZIP archive
products <- list.files(pattern=prefix)
products_fn <- glue::glue("{prefix}_products.zip")
zip(zipfile = products_fn, files = products)

# Create a resource for the ZIP archive
# d <- ckanr::package_show("turtle-tracks")
# r <- resource_create(package_id=d$id, name="Care for Hedland figures", upload=products_fn)

# Update resources on data catalogue 
ckanr::resource_update("b35fb19e-e72d-420c-b875-12b4db4afe8c", "pthedland_2017-18.html")
ckanr::resource_update("d8c309c4-66c2-449f-bdb3-5f41d3f15315", products_fn)
```

## Google Drive
A copy of this report and all generated outputs is uploaded to Google Drive
and shared via link with DBCA external collaborators.

Every machine has to be authenticated with Google Drive once.
As this process involves browser windows and pasting of approval codes into the 
R Console, it is not run automatically when compiling this workbook.

Running the following chunk manually once per machine will cache the authentication
token locally for future use.

```{r google_drive_auth, eval=F}
googledrive::drive_auth(reset=TRUE, use_oob = TRUE)
```

```{r google_drive_upload}
googledrive::drive_ls(prefix) %>% googledrive::drive_rm(.)
googledrive::drive_upload("pthedland_2017-18.html", path=glue::glue("{prefix}/pthedland_2017-18.html"))
products %>% purrr::map(googledrive::drive_upload, path=as_dribble(prefix))
```
